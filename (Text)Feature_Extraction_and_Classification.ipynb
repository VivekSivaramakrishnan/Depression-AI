{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(Text)Feature Extraction and Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VivekSivaramakrishnan/Depression-AI/blob/master/(Text)Feature_Extraction_and_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "y0WA4FyupvWw",
        "colab_type": "code",
        "outputId": "e016e626-b06f-4fd1-f42f-a8ba644b9397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "import nltk.data\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "word_tokenizer = TweetTokenizer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Example\n",
        "lemmatizer.lemmatize('geese')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'goose'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "Ir-RWyeDpvXI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sSuzLLFFq91g",
        "colab_type": "code",
        "outputId": "0f521298-df86-4f11-d2f3-627158f2e191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://github.com/singhalprerana/SST_data_extraction/archive/master.zip\n",
        "  \n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('master.zip', 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-17 06:36:40--  https://github.com/singhalprerana/SST_data_extraction/archive/master.zip\n",
            "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/singhalprerana/SST_data_extraction/zip/master [following]\n",
            "--2019-03-17 06:36:40--  https://codeload.github.com/singhalprerana/SST_data_extraction/zip/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 192.30.253.121, 192.30.253.120\n",
            "Connecting to codeload.github.com (codeload.github.com)|192.30.253.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip.1’\n",
            "\n",
            "master.zip.1            [       <=>          ]  13.31M  5.18MB/s    in 2.6s    \n",
            "\n",
            "2019-03-17 06:36:43 (5.18 MB/s) - ‘master.zip.1’ saved [13955306]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BjFuB-cGrTmr",
        "colab_type": "code",
        "outputId": "e76a6683-cf48-47c3-c7b5-cba3fb5e745c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "cell_type": "code",
      "source": [
        "!ls SST_data_extraction-master/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datasetSentences.txt\t  SOStr.txt\t\t    sst_test.csv\n",
            "datasetSplit.txt\t  sst5_dev.csv\t\t    sst_train_phrases.csv\n",
            "dictionary.txt\t\t  sst5_test.csv\t\t    sst_train_sentences.csv\n",
            "original_rt_snippets.txt  sst5_train_phrases.csv    STree.txt\n",
            "README.txt\t\t  sst5_train_sentences.csv  xtract_sst.py\n",
            "sentiment_labels.txt\t  sst_dev.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Pb70NKtIrZcB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This file includes:\n",
        "# 1. original_rt_snippets.txt contains 10,605 processed snippets from the original pool of Rotten Tomatoes HTML files. Please note that some snippet may contain multiple sentences.\n",
        "\n",
        "# 2. dictionary.txt contains all phrases and their IDs, separated by a vertical line |\n",
        "\n",
        "# 3. sentiment_labels.txt contains all phrase ids and the corresponding sentiment labels, separated by a vertical line.\n",
        "# Note that you can recover the 5 classes by mapping the positivity probability using the following cut-offs:\n",
        "# [0, 0.2], (0.2, 0.4], (0.4, 0.6], (0.6, 0.8], (0.8, 1.0]\n",
        "# for very negative, negative, neutral, positive, very positive, respectively.\n",
        "# Please note that phrase ids and sentence ids are not the same.\n",
        "\n",
        "# 4. SOStr.txt and STree.txt encode the structure of the parse trees. \n",
        "# STree encodes the trees in a parent pointer format. Each line corresponds to each sentence in the datasetSentences.txt file. The Matlab code of this paper will show you how to read this format if you are not familiar with it.\n",
        "\n",
        "# 5. datasetSentences.txt contains the sentence index, followed by the sentence string separated by a tab. These are the sentences of the train/dev/test sets.\n",
        "\n",
        "# 6. datasetSplit.txt contains the sentence index (corresponding to the index in datasetSentences.txt file) followed by the set label separated by a comma:\n",
        "# \t1 = train\n",
        "# \t2 = test\n",
        "# \t3 = dev\n",
        "\n",
        "# Please note that the datasetSentences.txt file has more sentences/lines than the original_rt_snippet.txt. \n",
        "# Each row in the latter represents a snippet as shown on RT, whereas the former is each sub sentence as determined by the Stanford parser."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vI5qlxW1tVug",
        "colab_type": "code",
        "outputId": "9e153e63-01c1-485b-c6fd-0c151a18b3a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "lst = pd.read_csv('SST_data_extraction-master/sst_train_sentences.csv')\n",
        "lst.columns = ['labels', 'features']\n",
        "lst.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.70833</td>\n",
              "      <td>Despite the film 's shortcomings , the stories...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.26389</td>\n",
              "      <td>Despite its dry wit and compassion , the film ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.47222</td>\n",
              "      <td>The central character is n't complex enough to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.13889</td>\n",
              "      <td>Rifkin no doubt fancies himself something of a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.45833</td>\n",
              "      <td>Dodgy mixture of cutesy romance , dark satire ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.51389</td>\n",
              "      <td>The only time 8 Crazy Nights comes close to hi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.70833</td>\n",
              "      <td>... quite good at providing some good old fash...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.73611</td>\n",
              "      <td>The huskies are beautiful , the border collie ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.41667</td>\n",
              "      <td>There is so much plodding sensitivity .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.66667</td>\n",
              "      <td>At the end , when the now computerized Yoda fi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    labels                                           features\n",
              "0  0.70833  Despite the film 's shortcomings , the stories...\n",
              "1  0.26389  Despite its dry wit and compassion , the film ...\n",
              "2  0.47222  The central character is n't complex enough to...\n",
              "3  0.13889  Rifkin no doubt fancies himself something of a...\n",
              "4  0.45833  Dodgy mixture of cutesy romance , dark satire ...\n",
              "5  0.51389  The only time 8 Crazy Nights comes close to hi...\n",
              "6  0.70833  ... quite good at providing some good old fash...\n",
              "7  0.73611  The huskies are beautiful , the border collie ...\n",
              "8  0.41667            There is so much plodding sensitivity .\n",
              "9  0.66667  At the end , when the now computerized Yoda fi..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "BpvPfvJ0UgJW",
        "colab_type": "code",
        "outputId": "e8103b34-97b8-4c64-d45a-0a5c2ca1239c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "lst[:1].features[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Despite the film 's shortcomings , the stories are quietly moving .\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "0C9w6KS_t0wm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lst['features'] = lst['features'].apply(refine_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JMQdH_n5vVyI",
        "colab_type": "code",
        "outputId": "c05b308d-6809-416f-ade6-7d102cce0c0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "lst[:1].features[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['story', 'moving', 'Despite', 'quietly', 'shortcoming', 'film']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "BFqNwG-PpvXf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def refine_sentence(word):\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    tokenized = word_tokenizer.tokenize(word)\n",
        "    cleaned_and_stemmed = [lemmatizer.lemmatize(i) for i in tokenized if i not in stop_words]\n",
        "    no_punctuation = list(set([i.translate(table) for i in cleaned_and_stemmed if i.translate(table)]))\n",
        "    return no_punctuation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RYL3H52jpvXm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "refined_lst = lst['features'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2PKkoIA6pvX-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "freqDist = nltk.FreqDist([i for j in refined_lst for i in j])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ogo4bCqbpvYI",
        "colab_type": "code",
        "outputId": "ea4a2563-e8e0-4506-d9ee-c8e913bea750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 18786
        }
      },
      "cell_type": "code",
      "source": [
        "bag_of_words = sorted(list(freqDist), key=lambda i: freqDist[i])[::-1]\n",
        "# Top 100 words for feature extraction\n",
        "top_words = bag_of_words[:5000]\n",
        "top_words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['film',\n",
              " 'The',\n",
              " 'movie',\n",
              " 'A',\n",
              " 'It',\n",
              " 'nt',\n",
              " 'one',\n",
              " 'like',\n",
              " 'story',\n",
              " 'make',\n",
              " 'I',\n",
              " 'character',\n",
              " 'comedy',\n",
              " 'time',\n",
              " 'This',\n",
              " 'much',\n",
              " 'good',\n",
              " 'work',\n",
              " 'performance',\n",
              " 'way',\n",
              " 'even',\n",
              " 'funny',\n",
              " 'little',\n",
              " 'An',\n",
              " 'life',\n",
              " 'would',\n",
              " 'never',\n",
              " 'feel',\n",
              " 'director',\n",
              " 'get',\n",
              " 'may',\n",
              " 'enough',\n",
              " 'u',\n",
              " 'look',\n",
              " 'come',\n",
              " 'thing',\n",
              " 'best',\n",
              " 'If',\n",
              " 'could',\n",
              " 'There',\n",
              " 'drama',\n",
              " 'love',\n",
              " 'made',\n",
              " 'year',\n",
              " 'plot',\n",
              " 'bad',\n",
              " 'audience',\n",
              " 'take',\n",
              " 'really',\n",
              " 'something',\n",
              " 'many',\n",
              " 'well',\n",
              " 'action',\n",
              " 'minute',\n",
              " 'better',\n",
              " 'see',\n",
              " 'give',\n",
              " 'without',\n",
              " 'go',\n",
              " 'What',\n",
              " 'people',\n",
              " 'end',\n",
              " 'also',\n",
              " 'still',\n",
              " 'cast',\n",
              " 'might',\n",
              " 'picture',\n",
              " 'moment',\n",
              " 'actor',\n",
              " 'script',\n",
              " 'two',\n",
              " 'fun',\n",
              " 'every',\n",
              " 'sense',\n",
              " 'long',\n",
              " 'great',\n",
              " 'nothing',\n",
              " 'humor',\n",
              " 'new',\n",
              " 'ever',\n",
              " 'first',\n",
              " 'thriller',\n",
              " 'scene',\n",
              " 'lot',\n",
              " 'In',\n",
              " 'As',\n",
              " 'documentary',\n",
              " 'kind',\n",
              " 'But',\n",
              " 'find',\n",
              " 'You',\n",
              " 'tale',\n",
              " 'often',\n",
              " 'real',\n",
              " 'entertaining',\n",
              " 'seems',\n",
              " 'One',\n",
              " 'another',\n",
              " 'heart',\n",
              " 'quite',\n",
              " 'Hollywood',\n",
              " 'le',\n",
              " 'show',\n",
              " 'almost',\n",
              " 'family',\n",
              " 'keep',\n",
              " 'filmmaker',\n",
              " 'yet',\n",
              " 'rather',\n",
              " 'interesting',\n",
              " 'hard',\n",
              " 'screen',\n",
              " 'far',\n",
              " 'idea',\n",
              " 'world',\n",
              " 'want',\n",
              " 'seen',\n",
              " 'woman',\n",
              " 'big',\n",
              " 'ca',\n",
              " 'need',\n",
              " 'watch',\n",
              " 'acting',\n",
              " 'original',\n",
              " 'piece',\n",
              " 'material',\n",
              " 'laugh',\n",
              " 'point',\n",
              " 'subject',\n",
              " 'think',\n",
              " 'turn',\n",
              " 'American',\n",
              " 'dialogue',\n",
              " 'bit',\n",
              " 'romantic',\n",
              " 'lack',\n",
              " 'Like',\n",
              " 'While',\n",
              " 'play',\n",
              " 'know',\n",
              " 'old',\n",
              " 'worth',\n",
              " 'back',\n",
              " 'ultimately',\n",
              " 'seem',\n",
              " 'man',\n",
              " 'human',\n",
              " 'offer',\n",
              " 'right',\n",
              " 'cliche',\n",
              " 'making',\n",
              " 'With',\n",
              " 'flick',\n",
              " 'young',\n",
              " 'matter',\n",
              " 'emotional',\n",
              " 'compelling',\n",
              " 'fan',\n",
              " 'experience',\n",
              " 'least',\n",
              " 'say',\n",
              " 'kid',\n",
              " 'though',\n",
              " 'place',\n",
              " 'watching',\n",
              " 'style',\n",
              " 'hour',\n",
              " 'fascinating',\n",
              " 'cinema',\n",
              " 'music',\n",
              " 'problem',\n",
              " 'For',\n",
              " 'set',\n",
              " 'direction',\n",
              " 'special',\n",
              " 'comic',\n",
              " 'viewer',\n",
              " 'screenplay',\n",
              " 'actually',\n",
              " 'together',\n",
              " 'moving',\n",
              " 'going',\n",
              " 'history',\n",
              " 'Not',\n",
              " 'child',\n",
              " 'full',\n",
              " 'dark',\n",
              " 'short',\n",
              " 'anything',\n",
              " 'visual',\n",
              " 'effect',\n",
              " 'art',\n",
              " 'genre',\n",
              " 'dull',\n",
              " 'care',\n",
              " 'charm',\n",
              " 'away',\n",
              " 'put',\n",
              " 'effort',\n",
              " 'feature',\n",
              " 'entertainment',\n",
              " 'star',\n",
              " 'whole',\n",
              " 'title',\n",
              " 'pretty',\n",
              " 'manages',\n",
              " 'since',\n",
              " 'day',\n",
              " 'part',\n",
              " 'try',\n",
              " 'premise',\n",
              " 'simply',\n",
              " 'probably',\n",
              " 'All',\n",
              " 'anyone',\n",
              " 'sometimes',\n",
              " 'always',\n",
              " 'clever',\n",
              " 'around',\n",
              " 'series',\n",
              " 'Though',\n",
              " 'cinematic',\n",
              " 'line',\n",
              " 'Even',\n",
              " 'last',\n",
              " 'Mr',\n",
              " 'video',\n",
              " 'narrative',\n",
              " 'engaging',\n",
              " 'whose',\n",
              " 'done',\n",
              " 'New',\n",
              " 'exercise',\n",
              " 'attempt',\n",
              " 'silly',\n",
              " 'portrait',\n",
              " 'familiar',\n",
              " 'predictable',\n",
              " 'shot',\n",
              " 'level',\n",
              " 'enjoyable',\n",
              " 'nearly',\n",
              " 'true',\n",
              " 'message',\n",
              " 'theater',\n",
              " 'energy',\n",
              " 'three',\n",
              " 'horror',\n",
              " 'strong',\n",
              " 'especially',\n",
              " 'version',\n",
              " 'worst',\n",
              " 'fall',\n",
              " 'No',\n",
              " 'power',\n",
              " 'wo',\n",
              " 'culture',\n",
              " 'sweet',\n",
              " 'study',\n",
              " 'feeling',\n",
              " 'joke',\n",
              " 'reason',\n",
              " 'face',\n",
              " 'trying',\n",
              " 'amusing',\n",
              " 'word',\n",
              " 'easy',\n",
              " 'romance',\n",
              " 'Despite',\n",
              " 'mind',\n",
              " 'powerful',\n",
              " 'certainly',\n",
              " 'eye',\n",
              " 'becomes',\n",
              " 'sequel',\n",
              " 'relationship',\n",
              " 'And',\n",
              " 'filmmaking',\n",
              " 'tone',\n",
              " 'else',\n",
              " 'smart',\n",
              " 'tell',\n",
              " 'classic',\n",
              " 'everything',\n",
              " 'pleasure',\n",
              " 'surprisingly',\n",
              " 'debut',\n",
              " 'John',\n",
              " 'French',\n",
              " 'image',\n",
              " 'sequence',\n",
              " 'That',\n",
              " 'dramatic',\n",
              " 'gag',\n",
              " 'high',\n",
              " 'book',\n",
              " 'beautiful',\n",
              " 'interest',\n",
              " 'charming',\n",
              " 'surprise',\n",
              " 'start',\n",
              " 'either',\n",
              " 'melodrama',\n",
              " 'sure',\n",
              " 'lead',\n",
              " 'At',\n",
              " 'wit',\n",
              " 'looking',\n",
              " 'believe',\n",
              " 'likely',\n",
              " 'ending',\n",
              " 'obvious',\n",
              " 'solid',\n",
              " 'talent',\n",
              " 'half',\n",
              " 'spirit',\n",
              " 'enjoy',\n",
              " 'rare',\n",
              " 'become',\n",
              " 'act',\n",
              " 'emotion',\n",
              " 'situation',\n",
              " 'quirky',\n",
              " 'modern',\n",
              " 'result',\n",
              " 'sort',\n",
              " 'camera',\n",
              " 'instead',\n",
              " 'stuff',\n",
              " 'war',\n",
              " 'opera',\n",
              " 'deeply',\n",
              " 'beautifully',\n",
              " 'social',\n",
              " 'light',\n",
              " 'leave',\n",
              " 'side',\n",
              " 'element',\n",
              " 'role',\n",
              " 'fact',\n",
              " 'event',\n",
              " 'already',\n",
              " 'completely',\n",
              " 'directed',\n",
              " 'run',\n",
              " 'crime',\n",
              " 'tragedy',\n",
              " 'teen',\n",
              " 'boring',\n",
              " 'intelligent',\n",
              " 'along',\n",
              " 'fine',\n",
              " 'left',\n",
              " 'small',\n",
              " 'Just',\n",
              " 'political',\n",
              " 'must',\n",
              " 'theme',\n",
              " 'ride',\n",
              " 'head',\n",
              " 'hit',\n",
              " 'intelligence',\n",
              " 'fresh',\n",
              " 'My',\n",
              " 'everyone',\n",
              " 'remains',\n",
              " 'suspense',\n",
              " 'help',\n",
              " 'prof',\n",
              " 'production',\n",
              " 'guy',\n",
              " 'mess',\n",
              " 'twist',\n",
              " 'fails',\n",
              " 'serious',\n",
              " 'Its',\n",
              " 'particularly',\n",
              " 'beyond',\n",
              " 'question',\n",
              " 'Love',\n",
              " 'animation',\n",
              " 'truly',\n",
              " 'summer',\n",
              " 'recent',\n",
              " 'sound',\n",
              " 'hold',\n",
              " 'storytelling',\n",
              " 'satisfying',\n",
              " 'stand',\n",
              " 'game',\n",
              " 'When',\n",
              " 'About',\n",
              " 'project',\n",
              " 'hero',\n",
              " 'passion',\n",
              " 'neither',\n",
              " 'Although',\n",
              " 'hilarious',\n",
              " 'mean',\n",
              " 'adventure',\n",
              " 'sad',\n",
              " 'adult',\n",
              " 'mystery',\n",
              " 'We',\n",
              " 'fantasy',\n",
              " 'TV',\n",
              " 'case',\n",
              " 'death',\n",
              " 'found',\n",
              " 'touching',\n",
              " 'perfect',\n",
              " 'despite',\n",
              " 'rich',\n",
              " 'seeing',\n",
              " 'thought',\n",
              " 'capture',\n",
              " 'mostly',\n",
              " 'artist',\n",
              " 'men',\n",
              " 'easily',\n",
              " 'mood',\n",
              " 'Director',\n",
              " 'complex',\n",
              " '2',\n",
              " 'writing',\n",
              " 'next',\n",
              " 'past',\n",
              " 'flat',\n",
              " 'impossible',\n",
              " 'comingofage',\n",
              " 'let',\n",
              " 'change',\n",
              " 'intriguing',\n",
              " 'touch',\n",
              " 'writer',\n",
              " 'satire',\n",
              " 'honest',\n",
              " 'contrived',\n",
              " 'terrific',\n",
              " 'different',\n",
              " 'bland',\n",
              " 'formula',\n",
              " 'violence',\n",
              " 'By',\n",
              " 'delivers',\n",
              " 'Time',\n",
              " 'memorable',\n",
              " 'live',\n",
              " 'value',\n",
              " 'running',\n",
              " 'add',\n",
              " 'pretentious',\n",
              " 'getting',\n",
              " 'soap',\n",
              " 'appeal',\n",
              " 'brilliant',\n",
              " 'actress',\n",
              " 'entirely',\n",
              " 'given',\n",
              " 'tired',\n",
              " 'Too',\n",
              " 'boy',\n",
              " 'amount',\n",
              " 'Michael',\n",
              " 'otherwise',\n",
              " 'wrong',\n",
              " 'got',\n",
              " 'reality',\n",
              " 'whether',\n",
              " 'difficult',\n",
              " 'finally',\n",
              " 'issue',\n",
              " 'surprising',\n",
              " 'age',\n",
              " 'II',\n",
              " 'Has',\n",
              " 'thoughtful',\n",
              " 'cut',\n",
              " 'plenty',\n",
              " 'girl',\n",
              " 'air',\n",
              " 'dumb',\n",
              " 'standard',\n",
              " 'remarkable',\n",
              " 'To',\n",
              " 'imagination',\n",
              " 'lost',\n",
              " 'Big',\n",
              " 'told',\n",
              " '90',\n",
              " 'concept',\n",
              " 'slow',\n",
              " 'home',\n",
              " 'Some',\n",
              " 'hand',\n",
              " 'cold',\n",
              " 'emotionally',\n",
              " 'Disney',\n",
              " 'insight',\n",
              " 'leaf',\n",
              " 'psychological',\n",
              " 'personal',\n",
              " 'term',\n",
              " 'He',\n",
              " 'approach',\n",
              " 'detail',\n",
              " 'fairly',\n",
              " 'written',\n",
              " 'engrossing',\n",
              " 'journey',\n",
              " 'sex',\n",
              " 'wonderful',\n",
              " 'period',\n",
              " 'flaw',\n",
              " 'mark',\n",
              " 'quality',\n",
              " 'vision',\n",
              " 'parent',\n",
              " 'job',\n",
              " 'close',\n",
              " 'moral',\n",
              " 'memory',\n",
              " 'rest',\n",
              " 'call',\n",
              " 'begin',\n",
              " 'Is',\n",
              " 'possible',\n",
              " 'final',\n",
              " 'So',\n",
              " 'execution',\n",
              " 'occasionally',\n",
              " 'novel',\n",
              " 'attention',\n",
              " 'view',\n",
              " 'straight',\n",
              " 'They',\n",
              " 'taste',\n",
              " 'inside',\n",
              " 'acted',\n",
              " 'appealing',\n",
              " 'remake',\n",
              " 'thrill',\n",
              " 'episode',\n",
              " 'thin',\n",
              " 'gone',\n",
              " 'present',\n",
              " 'historical',\n",
              " 'epic',\n",
              " 'thoroughly',\n",
              " 'credit',\n",
              " 'us',\n",
              " 'usual',\n",
              " 'unsettling',\n",
              " 'perfectly',\n",
              " 'David',\n",
              " 'cartoon',\n",
              " 'latest',\n",
              " 'Grant',\n",
              " 'More',\n",
              " 'force',\n",
              " 'second',\n",
              " 'excellent',\n",
              " 'somewhat',\n",
              " 'overall',\n",
              " 'depth',\n",
              " 'barely',\n",
              " 'career',\n",
              " 'simple',\n",
              " 'black',\n",
              " 'certain',\n",
              " 'odd',\n",
              " 'York',\n",
              " 'success',\n",
              " 'awful',\n",
              " 'tedious',\n",
              " 'able',\n",
              " 'saw',\n",
              " 'creative',\n",
              " 'single',\n",
              " 'Robert',\n",
              " 'drag',\n",
              " 'adaptation',\n",
              " 'After',\n",
              " 'date',\n",
              " 'De',\n",
              " 'delightful',\n",
              " 'exactly',\n",
              " 'Spielberg',\n",
              " 'ambitious',\n",
              " 'merely',\n",
              " 'flawed',\n",
              " 'number',\n",
              " 'entire',\n",
              " 'watchable',\n",
              " 'bring',\n",
              " 'dream',\n",
              " 'supposed',\n",
              " 'sentimental',\n",
              " 'monster',\n",
              " 'stupid',\n",
              " 'expect',\n",
              " 'felt',\n",
              " 'gentle',\n",
              " 'promise',\n",
              " 'fit',\n",
              " 'scary',\n",
              " 'strange',\n",
              " 'upon',\n",
              " 'process',\n",
              " 'nature',\n",
              " 'score',\n",
              " 'Allen',\n",
              " 'use',\n",
              " 'hope',\n",
              " 'manner',\n",
              " 'pace',\n",
              " 'scifi',\n",
              " 'couple',\n",
              " 'visually',\n",
              " 'impact',\n",
              " 'taking',\n",
              " 'soul',\n",
              " 'examination',\n",
              " 'deep',\n",
              " 'Nothing',\n",
              " 'America',\n",
              " 'sit',\n",
              " 'impressive',\n",
              " 'name',\n",
              " 'Full',\n",
              " 'nice',\n",
              " 'convincing',\n",
              " 'clear',\n",
              " 'used',\n",
              " 'low',\n",
              " 'delight',\n",
              " 'motion',\n",
              " 'sharp',\n",
              " 'treat',\n",
              " 'slight',\n",
              " 'effective',\n",
              " 'cheap',\n",
              " 'previous',\n",
              " 'across',\n",
              " 'figure',\n",
              " 'stylish',\n",
              " 'welcome',\n",
              " 'animated',\n",
              " 'sustain',\n",
              " 'magic',\n",
              " 'potential',\n",
              " 'rarely',\n",
              " 'someone',\n",
              " 'playing',\n",
              " 'edge',\n",
              " 'worse',\n",
              " 'oldfashioned',\n",
              " 'deal',\n",
              " 'tension',\n",
              " 'female',\n",
              " 'opportunity',\n",
              " 'plain',\n",
              " 'pure',\n",
              " 'creepy',\n",
              " 'throughout',\n",
              " 'routine',\n",
              " 'gorgeous',\n",
              " 'pull',\n",
              " 'creates',\n",
              " 'others',\n",
              " 'cool',\n",
              " 'Thing',\n",
              " 'pay',\n",
              " 'move',\n",
              " 'doubt',\n",
              " 'pacing',\n",
              " 'mother',\n",
              " 'mediocre',\n",
              " 'Every',\n",
              " 'ugly',\n",
              " 'subtle',\n",
              " 'lacking',\n",
              " 'coming',\n",
              " 'writerdirector',\n",
              " 'era',\n",
              " 'truth',\n",
              " 'genuine',\n",
              " 'frame',\n",
              " 'wonder',\n",
              " 'War',\n",
              " 'working',\n",
              " 'none',\n",
              " 'talented',\n",
              " 'imagine',\n",
              " 'sexual',\n",
              " 'form',\n",
              " 'Home',\n",
              " 'contemporary',\n",
              " 'urban',\n",
              " 'school',\n",
              " 'ability',\n",
              " 'waste',\n",
              " 'decent',\n",
              " 'successful',\n",
              " 'four',\n",
              " 'Jackson',\n",
              " 'warm',\n",
              " 'How',\n",
              " 'purpose',\n",
              " 'painful',\n",
              " 'several',\n",
              " 'carry',\n",
              " 'business',\n",
              " 'sign',\n",
              " 'melodramatic',\n",
              " 'seat',\n",
              " 'important',\n",
              " 'mix',\n",
              " 'behind',\n",
              " 'goofy',\n",
              " 'earnest',\n",
              " 'masterpiece',\n",
              " 'winning',\n",
              " 'deserves',\n",
              " 'fully',\n",
              " 'sincere',\n",
              " 'World',\n",
              " 'Do',\n",
              " 'among',\n",
              " 'weird',\n",
              " 'match',\n",
              " 'cultural',\n",
              " 'utterly',\n",
              " 'Chan',\n",
              " 'Steven',\n",
              " 'decade',\n",
              " 'casting',\n",
              " 'ensemble',\n",
              " 'major',\n",
              " 'hardly',\n",
              " 'definitely',\n",
              " 'chemistry',\n",
              " 'share',\n",
              " 'reveals',\n",
              " 'worthy',\n",
              " 'unique',\n",
              " 'mildly',\n",
              " 'meditation',\n",
              " 'five',\n",
              " 'unexpected',\n",
              " 'Man',\n",
              " 'clearly',\n",
              " 'stunt',\n",
              " 'British',\n",
              " 'rise',\n",
              " 'slightly',\n",
              " 'skill',\n",
              " 'stay',\n",
              " 'unfunny',\n",
              " 'quiet',\n",
              " 'future',\n",
              " 'setting',\n",
              " 'battle',\n",
              " 'Movie',\n",
              " 'apart',\n",
              " 'exciting',\n",
              " '2002',\n",
              " 'Blade',\n",
              " 'called',\n",
              " 'create',\n",
              " 'member',\n",
              " 'class',\n",
              " 'screenwriter',\n",
              " 'Williams',\n",
              " 'glimpse',\n",
              " 'understand',\n",
              " 'Watching',\n",
              " 'provides',\n",
              " 'finish',\n",
              " 'loud',\n",
              " 'huge',\n",
              " 'treatment',\n",
              " 'witty',\n",
              " 'derivative',\n",
              " 'Oscar',\n",
              " 'sport',\n",
              " 'provocative',\n",
              " 'college',\n",
              " 'shock',\n",
              " 'however',\n",
              " 'Solondz',\n",
              " 'hate',\n",
              " 'friendship',\n",
              " 'Those',\n",
              " 'viewing',\n",
              " 'considerable',\n",
              " 'gay',\n",
              " 'Tom',\n",
              " 'storyline',\n",
              " 'crafted',\n",
              " 'brain',\n",
              " 'target',\n",
              " 'suffers',\n",
              " 'dry',\n",
              " 'tragic',\n",
              " 'poorly',\n",
              " 'extreme',\n",
              " 'spectacle',\n",
              " 'X',\n",
              " 'humanity',\n",
              " 'Bullock',\n",
              " 'atmosphere',\n",
              " 'justice',\n",
              " 'said',\n",
              " 'Feels',\n",
              " 'intimate',\n",
              " 'eventually',\n",
              " 'terrible',\n",
              " 'virtually',\n",
              " 'Does',\n",
              " 'recommend',\n",
              " 'Crush',\n",
              " 'interested',\n",
              " 'appears',\n",
              " 'involved',\n",
              " 'road',\n",
              " 'generic',\n",
              " 'involving',\n",
              " 'warmth',\n",
              " 'trick',\n",
              " 'insightful',\n",
              " 'personality',\n",
              " 'seriously',\n",
              " 'taken',\n",
              " 'sexy',\n",
              " 'uneven',\n",
              " '10',\n",
              " 'predecessor',\n",
              " 'thanks',\n",
              " 'lovely',\n",
              " 'win',\n",
              " 'answer',\n",
              " 'break',\n",
              " 'heartfelt',\n",
              " 'car',\n",
              " 'brings',\n",
              " 'equally',\n",
              " 'based',\n",
              " 'substance',\n",
              " 'heavy',\n",
              " 'wind',\n",
              " 'succeeds',\n",
              " 'triumph',\n",
              " 'popcorn',\n",
              " 'thinking',\n",
              " 'T',\n",
              " 'middle',\n",
              " 'quickly',\n",
              " 'inventive',\n",
              " 'dog',\n",
              " 'sensitive',\n",
              " 'protagonist',\n",
              " 'complete',\n",
              " 'rhythm',\n",
              " 'highly',\n",
              " 'sitting',\n",
              " 'folk',\n",
              " 'room',\n",
              " 'Soderbergh',\n",
              " 'beauty',\n",
              " 'depressing',\n",
              " 'usually',\n",
              " 'sophisticated',\n",
              " 'George',\n",
              " 'except',\n",
              " 'wish',\n",
              " 'poetry',\n",
              " 'wear',\n",
              " 'course',\n",
              " 'lie',\n",
              " 'bore',\n",
              " 'expectation',\n",
              " 'Much',\n",
              " 'Never',\n",
              " 'affair',\n",
              " 'frequently',\n",
              " 'Brown',\n",
              " 'believable',\n",
              " 'cute',\n",
              " 'tribute',\n",
              " 'Both',\n",
              " 'giving',\n",
              " 'hole',\n",
              " 'conclusion',\n",
              " 'allows',\n",
              " 'painfully',\n",
              " 'franchise',\n",
              " 'ago',\n",
              " 'pointless',\n",
              " 'chance',\n",
              " 'Rock',\n",
              " 'gripping',\n",
              " 'victim',\n",
              " 'created',\n",
              " 'Day',\n",
              " 'core',\n",
              " 'Sandler',\n",
              " 'absolutely',\n",
              " 'riveting',\n",
              " 'manipulative',\n",
              " 'shallow',\n",
              " 'missing',\n",
              " 'performer',\n",
              " 'empty',\n",
              " 'maybe',\n",
              " 'money',\n",
              " 'inspired',\n",
              " 'save',\n",
              " 'strength',\n",
              " 'fear',\n",
              " 'Martin',\n",
              " 'liked',\n",
              " 'fill',\n",
              " 'worthwhile',\n",
              " 'top',\n",
              " 'conventional',\n",
              " 'type',\n",
              " 'song',\n",
              " 'release',\n",
              " 'pleasant',\n",
              " 'endearing',\n",
              " 'overcome',\n",
              " 'forgettable',\n",
              " 'Moore',\n",
              " 'struggle',\n",
              " 'wanted',\n",
              " 'alone',\n",
              " 'funnier',\n",
              " 'observation',\n",
              " 'Murphy',\n",
              " 'today',\n",
              " 'open',\n",
              " 'Ms',\n",
              " 'body',\n",
              " 'telling',\n",
              " 'typical',\n",
              " 'pop',\n",
              " 'Spy',\n",
              " 'colorful',\n",
              " 'de',\n",
              " 'poor',\n",
              " 'bizarre',\n",
              " 'filled',\n",
              " 'intended',\n",
              " 'living',\n",
              " 'space',\n",
              " 'grace',\n",
              " 'central',\n",
              " 'quietly',\n",
              " 'conviction',\n",
              " 'color',\n",
              " 'aspect',\n",
              " 'fiction',\n",
              " 'forced',\n",
              " 'extremely',\n",
              " 'slapstick',\n",
              " 'sight',\n",
              " 'crowd',\n",
              " 'essentially',\n",
              " 'simplistic',\n",
              " 'fare',\n",
              " 'particular',\n",
              " 'Ryan',\n",
              " 'perspective',\n",
              " 'smile',\n",
              " 'needed',\n",
              " 'main',\n",
              " 'Seagal',\n",
              " 'From',\n",
              " 'provide',\n",
              " 'loss',\n",
              " 'wildly',\n",
              " 'Heaven',\n",
              " 'visuals',\n",
              " 'strangely',\n",
              " 'Who',\n",
              " 'skin',\n",
              " 'Instead',\n",
              " 'faith',\n",
              " 'emerges',\n",
              " 'directorial',\n",
              " 'Lee',\n",
              " 'Wild',\n",
              " 'Girl',\n",
              " 'company',\n",
              " 'conflict',\n",
              " 'joy',\n",
              " 'party',\n",
              " 'vivid',\n",
              " 'document',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "157nyXHJbawm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('topWords.pkl', 'wb') as f:\n",
        "  pickle.dump(top_words, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WvrY4I96pvYX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features = []\n",
        "for sentence in refined_lst:\n",
        "    features.append([int(top_word in sentence) for top_word in top_words])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1LJR_sMHxEIm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels = [int(i>=0.5) for i in lst['labels'].tolist()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8GckIOzBpvYu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Shuffle the features and labels\n",
        "import random\n",
        "lsst = list(zip(features, labels))\n",
        "random.shuffle(lsst)\n",
        "features, labels = zip(*lsst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4gkEqFl7xz3f",
        "colab_type": "code",
        "outputId": "fc5232c1-f774-4271-89df-4cc45be43f60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "# int(label_frame['sentiment values'].tolist()[13] >= 0.6)\n",
        "len(features), len(labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8533, 8533)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "1GuYwEUppvY1",
        "colab_type": "code",
        "outputId": "283672fc-b0fb-4ca0-ac41-277b220a52dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "cell_type": "code",
      "source": [
        "# Training\n",
        "X, y = list(features), list(labels)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_moons, make_circles, make_classification\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=42)\n",
        "\n",
        "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
        "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
        "         \"Naive Bayes\", \"QDA\"]\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(3),\n",
        "    SVC(kernel=\"linear\", C=0.025),\n",
        "    SVC(gamma=2, C=1),\n",
        "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
        "    DecisionTreeClassifier(max_depth=5),\n",
        "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "    MLPClassifier(alpha=1),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    QuadraticDiscriminantAnalysis()]\n",
        "\n",
        "# Testing\n",
        "for name, clf in zip(names, classifiers):\n",
        "    clf.fit(X_train, y_train)\n",
        "    score = clf.score(X_test, y_test)\n",
        "    print('{} scored: {}'.format(name, score))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nearest Neighbors scored: 0.5351493848857645\n",
            "Linear SVM scored: 0.6549502050380785\n",
            "RBF SVM scored: 0.526654950205038\n",
            "Gaussian Process scored: 0.5222612770943175\n",
            "Decision Tree scored: 0.5556531927357938\n",
            "Random Forest scored: 0.5199179847685999\n",
            "Neural Net scored: 0.7126537785588752\n",
            "AdaBoost scored: 0.6004686584651435\n",
            "Naive Bayes scored: 0.6063268892794376\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "QDA scored: 0.5536028119507909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AbJBItBdHpFs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Nearest Neighbors scored: 0.5351493848857645\n",
        "# Linear SVM scored: 0.6549502050380785\n",
        "# RBF SVM scored: 0.526654950205038\n",
        "# Gaussian Process scored: 0.5222612770943175\n",
        "# Decision Tree scored: 0.5556531927357938\n",
        "# Random Forest scored: 0.5199179847685999\n",
        "# Neural Net scored: 0.7126537785588752\n",
        "# AdaBoost scored: 0.6004686584651435\n",
        "# Naive Bayes scored: 0.6063268892794376\n",
        "# QDA scored: 0.5536028119507909\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "SMpHEmCTpvZB",
        "colab_type": "code",
        "outputId": "cee70a9a-b9f6-4d8d-8c30-b63c4e103e80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "cell_type": "code",
      "source": [
        "# Testing with user input\n",
        "while True:\n",
        "    t = input('Enter sentence: ')\n",
        "    if not t: break\n",
        "    name, clf = names[6], classifiers[6]\n",
        "        \n",
        "    ready_t = [int(top_word in refine_sentence(t)) for top_word in top_words]\n",
        "\n",
        "    ans = ['Depressed', 'Happy'][clf.predict([ready_t])[0]]\n",
        "\n",
        "    print('{} thinks you are: {}\\n'.format(name, ans))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter sentence: Head over heels\n",
            "Neural Net thinks you are: Happy\n",
            "\n",
            "Enter sentence: Best day ever\n",
            "Neural Net thinks you are: Happy\n",
            "\n",
            "Enter sentence: Happy as a clam\n",
            "Neural Net thinks you are: Happy\n",
            "\n",
            "Enter sentence: I am so excited today\n",
            "Neural Net thinks you are: Depressed\n",
            "\n",
            "Enter sentence: I can't wait to go out\n",
            "Neural Net thinks you are: Depressed\n",
            "\n",
            "Enter sentence: I am so happy\n",
            "Neural Net thinks you are: Happy\n",
            "\n",
            "Enter sentence: Lonely, that's all I am at this point\n",
            "Neural Net thinks you are: Depressed\n",
            "\n",
            "Enter sentence: I'm slowly giving up.\n",
            "Neural Net thinks you are: Happy\n",
            "\n",
            "Enter sentence: I have cried becaure you are you\n",
            "Neural Net thinks you are: Depressed\n",
            "\n",
            "Enter sentence: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y_pK1lDfI2k8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save model for use\n",
        "from sklearn.externals import joblib\n",
        "for name, clf in zip(names, classifiers):\n",
        "  joblib.dump(clf, name+'.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}